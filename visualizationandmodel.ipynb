{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dython in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (1.16.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (0.9.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (0.21.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (0.25.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from dython) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->dython) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->dython) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->dython) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->dython) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn->dython) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->dython) (2019.3)\n",
      "Requirement already satisfied: six in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->dython) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nmf2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->dython) (41.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dython.nominal import associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ObesityDataSet_raw_and_data_sinthetic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ca71f8798137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Importing the dataset from the same directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Creating a dataframe from the dataset and showcasing the first 10 results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./ObesityDataSet_raw_and_data_sinthetic.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdata_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ObesityDataSet_raw_and_data_sinthetic.csv'"
     ]
    }
   ],
   "source": [
    "#Importing the dataset from the same directory\n",
    "#Creating a dataframe from the dataset and showcasing the first 10 results\n",
    "file=open(\"./ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "data_raw=file.read().split(\"\\n\")\n",
    "data_list=[]\n",
    "for row in data_raw:\n",
    "    data_list.append(row.split(\",\"))\n",
    "data=pd.DataFrame(data_list[1:-1])\n",
    "data.columns=data_list[0]\n",
    "print(data.head(10))\n",
    "file.close()\n",
    "data_obesity=pd.read_csv(\"./ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "\n",
    "#data is a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#In the first part of this notebook we will study the dataset and visualize it.\n",
    "#The following command will give us the count of each attribute, how many unique values the attribute has,\n",
    "#the top inputs and the frequency of the top input.\n",
    "data_obesity.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will check whether any of the input value is null. \n",
    "data_obesity.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obesity.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also check the target values that are possible\n",
    "data_obesity.NObeyesdad.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also would like to know what the input values are for each attribute\n",
    "\n",
    "print(data_obesity.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Introducion\n",
    "## Attributes\n",
    "So far we can say that the data has no null values and that the target values are split into 7 types : \n",
    "1. Insufficient_Weight\n",
    "2. Normal Weight\n",
    "3. Overweight_Level_I\n",
    "4. Overweight_Level_II\n",
    "5. Obesity_Type_I\n",
    "6. Obesity_Type_II\n",
    "7. Obesity_Type_III\n",
    "\n",
    "The attribute for the target values is NObeyesdad. The rest of the attributes are:\n",
    "- Gender : Male/Female\n",
    "- Age : Numeric value\n",
    "- Height : Numeric value in m\n",
    "- Weight : Numeric value in kg\n",
    "- family_history_with_overweight : boolean\n",
    "\n",
    "- FAVC Frequent consumption of high caloric food : boolean\n",
    "- FCVC Frequency of consumption of vegetables : Never | Sometimes | Always\n",
    "- NCP Number of daily meals: Between 1 and 2 | Three | More than 3\n",
    "- CAEC: Frequency of Consumption of food between meals: No | Sometimes | Frequently | Always\n",
    "- SMOKE : boolean\n",
    "- CH2O Consumption of water  : Less than a liter, Between 1 and 2 L, More than 2 L\n",
    "- SCC Daily calorie monitoring : boolean\n",
    "- FAF Frequency of physical activity : NO | 1-2days | 2-4 days | 4-5 days\n",
    "- TUE Time spent on technological devices : 0-2 hours | 3-5 hours | more than 5 hours\n",
    "- CALC frequency of alcohol Consumption : No | Sometimes | Frequently | Always\n",
    "- MTRANS type of transport used : Automobile | Motrobike,Bike | Public Transportation | Walking\n",
    "\n",
    "## Influence of BMI on obesity levels\n",
    "\n",
    "It is clear that the BMI that is calculated based on the height and weight of an individual plays a big rol in classifying the individual in one of the 7 labels. The BMI is calculated as follows: \n",
    "Body Mass Index = Weight/(Height)^2 ; Where the weight is in Kg and the height in meters. \n",
    "\n",
    "The result of the BMI gives the following labelling: \n",
    "- Underweight Less than 18.5\n",
    "- Normal 18.5 to 24.9\n",
    "- Overweight 25.0 to 29.9\n",
    "- Obesity I 30.0 to 34.9\n",
    "- Obesity II 35.0 to 39.9\n",
    "- Obesity III Higher than 40\n",
    "\n",
    "However since the goal of this assignment is interpreted as seeing how all the attributes affect the result we will model two datasets. One including the height and weight and one without. This way a comparison can be performed and the best prediction model will be chosen. \n",
    "\n",
    "# Data visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will visualize the data that have various categories\n",
    "columns = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
    "           'SCC', 'CALC', 'MTRANS', 'NObeyesdad']\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for col, subplot in zip(columns, ax.flatten()):\n",
    "    sns.countplot(data[col], ax=subplot)\n",
    "    \n",
    "    if col==\"MTRANS\":\n",
    "        sns.countplot(data[col],ax=subplot)\n",
    "        subplot.set_xticklabels(rotation=45, horizontalalignment='right', labels=data.MTRANS.unique())        \n",
    "        subplot.yaxis.label.set_text(\"Number of Records\")\n",
    "    elif col==\"NObeyesdad\":\n",
    "        sns.countplot(data[col],ax=subplot)\n",
    "        subplot.set_xticklabels(rotation=45, horizontalalignment='right', labels=data.NObeyesdad.unique())  \n",
    "        subplot.yaxis.label.set_text(\"Number of Records\")\n",
    "    else:\n",
    "        sns.countplot(data[col],ax=subplot)  \n",
    "        subplot.yaxis.label.set_text(\"Number of Records\")\n",
    "        \n",
    "fig.suptitle(\"Attribute inputs\", fontsize=20)\n",
    "plt.tight_layout(pad=5, w_pad=0.0, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_obesity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c8b1ea916c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m g = sns.catplot(y=\"NObeyesdad\", hue=\"Gender\", kind=\"count\", \n\u001b[1;32m----> 2\u001b[1;33m             data=data_obesity)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_obesity' is not defined"
     ]
    }
   ],
   "source": [
    "g = sns.catplot(y=\"NObeyesdad\", hue=\"Gender\", kind=\"count\", \n",
    "            data=data_obesity)\n",
    "\n",
    "g.fig.set_figwidth(15)\n",
    "g.fig.set_figheight(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can see that the amount of male and female individuals are the same which should not impact the results. However this is not the case, a clear distinction can be made for almost all of the classes except the normal weight class and the first type of overweight class. This might indicate that the gender plays a very important role in assigning the labels to each individual. The rest of the attribute that have a categorical input showcase a clear distinction between each of the input choices. With the next visualization techniques, we will look at which of the attributes seem to be the most signigicant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following plot will show a scatter plot of each of the 15 attributes.\n",
    "pd.plotting.scatter_matrix(data_obesity,figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next command will allow us to create a heatmap to indicate the importance and correlation of each of the attributes in the target definition\n",
    "associations(data_obesity, figsize = (15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As previously explained, the correlation between the target attribute and weight seems very high. Which agrees with our previously made hypothesis that the results heavenly rely on the BMI. However, the heatmap also shows a high correlation between the Gender and the target attribute NObeyesdad. The next important attributes are : \n",
    " \n",
    "- Family history with overweight\n",
    "- FCVC\n",
    "- AGE \n",
    "- CAEC \n",
    "- FAVC \n",
    "in that order. \n",
    "\n",
    "Some of these attributes will be looked at closer during the visualization phase to gain more insight.\n",
    "\n",
    "## Family history with overweight\n",
    "First we will start with the attribute showcasing the family history with overweight. The input values for this attribute is boolean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_obesity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ed0ab78911bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m Family = sns.catplot(y=\"NObeyesdad\", hue=\"family_history_with_overweight\", kind=\"count\",\n\u001b[1;32m----> 2\u001b[1;33m             data=data_obesity)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFamily\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFamily\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_obesity' is not defined"
     ]
    }
   ],
   "source": [
    "Family = sns.catplot(y=\"NObeyesdad\", hue=\"family_history_with_overweight\", kind=\"count\",\n",
    "            data=data_obesity)\n",
    "\n",
    "Family.fig.set_figwidth(15)\n",
    "Family.fig.set_figheight(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that although for all the target except obesity type 2 and obesity type 3, there are some individuals suffering eventhough no history of overweight family members is detected. However, it can't be denied that the influence of family history is huge on all types of obesity and overweight type 1 and 2. This agrees with the many studies performed previously on the link of overweight family history and severe onset of obesitat.  Below links of some of the studies performed: \n",
    "- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5941161/\n",
    "- https://blog.frontiersin.org/2018/05/16/endocrinology-childhood-obesity-family-risk-factors/\n",
    "\n",
    "## Frequency consumption of high caloric food\n",
    "\n",
    "The next step is to determine how the frequency consumpton of food high in calories influences the various types of target labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_obesity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-573c5f660659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m FCVC = sns.catplot(y=\"NObeyesdad\", hue=\"FAVC\",kind='count',\n\u001b[1;32m----> 2\u001b[1;33m             data=data_obesity)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFCVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFCVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_obesity' is not defined"
     ]
    }
   ],
   "source": [
    "FCVC = sns.catplot(y=\"NObeyesdad\", hue=\"FAVC\",kind='count',\n",
    "            data=data_obesity)\n",
    "\n",
    "FCVC.fig.set_figwidth(15)\n",
    "FCVC.fig.set_figheight(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that most of the people answered with yes which mean the high amount of calories does not neccesarily influence the output. However, it can be noticed that the people with a normal weight do have a tendancy to eat less high caloric meals on a dialy basis. We can combine the results with those found with the previous attribute that showcases the influence of family history:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixing=data_obesity.pivot_table('Gender',index=\"NObeyesdad\",columns=[\"family_history_with_overweight\",\"FAVC\"],aggfunc='count')\n",
    "Mixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that most of the people that have a family members with history of obesity also tend to consume high calorie meals on a daily bases. The majority of these people have type 1 obesity closely followed by type 3 obesity. This is a very important remark since it tends to also show the link between having a family member that suffered or is suffering from obesity and the tendancy to eat more. \n",
    "## Age \n",
    "\n",
    "Next we will look at the age. The following boxplots will show the average age for each target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_obesity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8c3912afa462>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'NObeyesdad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_obesity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_obesity' is not defined"
     ]
    }
   ],
   "source": [
    "sns.boxplot(x = 'Age', y = 'NObeyesdad', data = data_obesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the targets have an average age between 20 and 30. This sounds counter intuitive since most of the people at that age are at their fittest. Therefore, we will plot a graph showcasing the age of the individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_obesity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-48a74d19a4c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_obesity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_obesity' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(data_obesity.Age)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the majority of the participants is between 20 and 30. This explains our previously found conclusions. However, the boxplots are not completely useless. The boxplots showcasing an average that leans toward the 30 indicates a very strong influence for the people that are above 30. Since this group of participants is small the numbers must be high. These include obesity type 2 and type 3.\n",
    "\n",
    "Note that since the majority of the participant is between 20 and 30 the age perimeter is not a good indication to use in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have visualized the data and gained a profound understand of what is happening. This insight will help us to create a predictive model in the next part of the assignment.\n",
    "\n",
    "# Preparing the data\n",
    "\n",
    "As explained previously, we will create two models one with the height and weight and one without. In addition, the different strings in the attributes will be transformed to categories. (Other encoding processes are possible with different libraries however this seemed to be the most straightforward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding strings to categories\n",
    "columns = [\"Gender\",\"family_history_with_overweight\", \"FAVC\",\"FCVC\", \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\",\"FAF\",\"NCP\", \"NObeyesdad\",]\n",
    "\n",
    "for col in columns:\n",
    "    data_obesity[col] = data_obesity[col].astype('category')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "data_obesity['CAEC'] = labelEncoder.fit_transform(data_obesity['CAEC'])\n",
    "data_obesity['CALC'] = labelEncoder.fit_transform(data_obesity['CALC'])\n",
    "\n",
    "data_obesity2=data_obesity.drop(columns=['Height','Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2111 entries, 0 to 2110\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   Gender                          2111 non-null   category\n",
      " 1   Age                             2111 non-null   float64 \n",
      " 2   Height                          2111 non-null   float64 \n",
      " 3   Weight                          2111 non-null   float64 \n",
      " 4   family_history_with_overweight  2111 non-null   category\n",
      " 5   FAVC                            2111 non-null   category\n",
      " 6   FCVC                            2111 non-null   category\n",
      " 7   NCP                             2111 non-null   category\n",
      " 8   CAEC                            2111 non-null   category\n",
      " 9   SMOKE                           2111 non-null   category\n",
      " 10  CH2O                            2111 non-null   float64 \n",
      " 11  SCC                             2111 non-null   category\n",
      " 12  FAF                             2111 non-null   category\n",
      " 13  TUE                             2111 non-null   float64 \n",
      " 14  CALC                            2111 non-null   category\n",
      " 15  MTRANS                          2111 non-null   category\n",
      " 16  NObeyesdad                      2111 non-null   category\n",
      "dtypes: category(12), float64(5)\n",
      "memory usage: 235.5 KB\n"
     ]
    }
   ],
   "source": [
    "data_obesity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is sufficiently prepared, we will look at some models.\n",
    "\n",
    "# Model creation\n",
    "\n",
    "In order to build a prediction model many machine learning algorithms can be applied. For this specific application the goal is to create a prediction model able to classify the individual based on the given attribute. This leaves us with the many options for classification algorithms. For this approach three types will be considered: \n",
    "\n",
    "- Decision tree model : In this model the algorithm creates many subtrees depending on the attribute input. \n",
    "- Random Forest model : This is an extension of the decision tree model.The Random Forest Algorithm combines the output of multiple (randomly created) Decision Trees to generate the final output.\n",
    "- KNN : KNN works by finding the distance between datapoints by selecting a number K of groups and classifying them by distance.\n",
    "\n",
    "Note: Boosting has also been briefly considered however when trying to run the model it took a significant amount of time and the accuracy was very close to the random forest model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset without the height and the weight \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Decision tree Model##########\n",
      "Precision of the DT Model: 0.8474 %\n",
      "Recall of the DT Model: 0.8474 %\n",
      "f1-score of the DT Model: 0.2615 %\n",
      "##########Random Forest Model##########\n",
      "Precision of the DT Model: 0.9726 %\n",
      "Recall of the DT Model: 0.9726 %\n",
      "f1-score of the DT Model: 0.4909 %\n",
      "##########KNN Model##########\n",
      "Precision of the DT Model: 0.6282 %\n",
      "Recall of the DT Model: 0.6282 %\n",
      "f1-score of the DT Model: 0.1811 %\n"
     ]
    }
   ],
   "source": [
    "# First we start with defining the different models\n",
    "DTClass=DecisionTreeClassifier()\n",
    "RFClass=RandomForestClassifier(random_state=2111)\n",
    "KNNClass=KNeighborsClassifier()\n",
    "# Now we will prepare the data\n",
    "dataPREP=data_obesity2.copy()\n",
    "dataPREP = pd.get_dummies(dataPREP,columns=[\"Gender\",\"family_history_with_overweight\",\n",
    "                                          \"FAVC\",\"FCVC\",\"CAEC\",\"SMOKE\",\"SCC\",\"CALC\",\"MTRANS\"])\n",
    "\n",
    "#We split the data into training set and test set by first removing the target values\n",
    "data_noTarget=pd.concat([dataPREP.loc[:, dataPREP.columns != 'NObeyesdad']])\n",
    "# Since there 2111 entries we will use approximately 70% for training\n",
    "TrainSet=data_noTarget[:1600]\n",
    "resultTrainSet=data_obesity2.NObeyesdad[:1600]\n",
    "\n",
    "TestSet=data_noTarget[1600:]\n",
    "resultTestSet=data_obesity2.NObeyesdad[1600:]\n",
    "\n",
    "#We will only use scaled data in our models\n",
    "\n",
    "standardScale=StandardScaler()\n",
    "TrainSetScaled=standardScale.fit_transform(TrainSet)\n",
    "TestSetScaled=standardScale.transform(TestSet)\n",
    "\n",
    "Target=data_obesity2.NObeyesdad\n",
    "# First we will start with the Decision tree model\n",
    "print(\"##########Decision tree Model##########\")\n",
    "DTModel=DTClass.fit(TrainSetScaled,resultTrainSet)\n",
    "DTPrediction=DTModel.predict(TestSetScaled)\n",
    "DTprecision = precision_score(resultTestSet, DTPrediction,average='micro') \n",
    "DTrecall = recall_score(resultTestSet, DTPrediction,average='weighted') \n",
    "DTf1score = f1_score(resultTestSet, DTPrediction,average='macro')\n",
    "print(\"Precision of the DT Model: %.4f %%\"%(DTprecision))\n",
    "print(\"Recall of the DT Model: %.4f %%\"%(DTrecall))\n",
    "print('f1-score of the DT Model: %.4f %%'%(DTf1score))\n",
    "\n",
    "print(\"##########Random Forest Model##########\")\n",
    "\n",
    "RFModel=RFClass.fit(TrainSetScaled,resultTrainSet)\n",
    "RFPrediction=RFModel.predict(TestSetScaled)\n",
    "RFprecision = precision_score(resultTestSet, RFPrediction,average='micro') \n",
    "RFrecall = recall_score(resultTestSet, RFPrediction,average='weighted') \n",
    "RFf1score = f1_score(resultTestSet, RFPrediction,average='macro')\n",
    "print(\"Precision of the RF Model: %.4f %%\"%(RFprecision))\n",
    "print(\"Recall of the RF Model: %.4f %%\"%(RFrecall))\n",
    "print('f1-score of the RF Model: %.4f %%'%(RFf1score))\n",
    "\n",
    "\n",
    "print(\"##########KNN Model##########\")\n",
    "KNNModel=KNNClass.fit(TrainSetScaled,resultTrainSet)\n",
    "KNNPrediction=KNNModel.predict(TestSetScaled)\n",
    "KNNprecision = precision_score(resultTestSet, KNNPrediction,average='micro') \n",
    "KNNrecall = recall_score(resultTestSet, KNNPrediction,average='weighted') \n",
    "KNNf1score = f1_score(resultTestSet, KNNPrediction,average='macro')\n",
    "print(\"Precision of the KNN Model: %.4f %%\"%(KNNprecision))\n",
    "print(\"Recall of the KNN Model: %.4f %%\"%(KNNrecall))\n",
    "print('f1-score of the KNN Model: %.4f %%'%(KNNf1score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can conclude that the Random Forest Model proved to be the  best model for our data set with an accuracy of 97%. \n",
    "\n",
    "###### Dataset with Height and Weight\n",
    "Next we will look at the dataset while including the height and the weight. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff64799434ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#The following code does not change much from the previous one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# First we start with defining the different models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mDTClass2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mRFClass2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mKNNClass2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#The following code does not change much from the previous one.\n",
    "# First we start with defining the different models\n",
    "DTClass2=DecisionTreeClassifier()\n",
    "RFClass2=RandomForestClassifier(random_state=2111)\n",
    "KNNClass2=KNeighborsClassifier()\n",
    "# Now we will prepare the data\n",
    "dataPREP2=data_obesity.copy()\n",
    "dataPREP2= pd.get_dummies(dataPREP2,columns=[\"Gender\",\"Height\",\"Weight\",\"family_history_with_overweight\",\n",
    "                                          \"FAVC\",\"FCVC\",\"CAEC\",\"SMOKE\",\"SCC\",\"CALC\",\"MTRANS\"])\n",
    "\n",
    "#We split the data into training set and test set by first removing the target values\n",
    "data_noTarget2=pd.concat([dataPREP2.loc[:, dataPREP2.columns != 'NObeyesdad']])\n",
    "# Since there 2111 entries we will use approximately 70% for training\n",
    "TrainSet2=data_noTarget2[:1600]\n",
    "resultTrainSet2=data_obesity.NObeyesdad[:1600]\n",
    "\n",
    "TestSet2=data_noTarget2[1600:]\n",
    "resultTestSet2=data_obesity2.NObeyesdad[1600:]\n",
    "\n",
    "#We will only use scaled data in our models\n",
    "\n",
    "standardScale=StandardScaler()\n",
    "TrainSetScaled2=standardScale.fit_transform(TrainSet2)\n",
    "TestSetScaled2=standardScale.transform(TestSet2)\n",
    "\n",
    "Target2=data_obesity.NObeyesdad\n",
    "# First we will start with the Decision tree model\n",
    "print(\"##########Decision tree Model##########\")\n",
    "DTModel2=DTClass.fit(TrainSetScaled2,resultTrainSet2)\n",
    "DTPrediction2=DTModel2.predict(TestSetScaled2)\n",
    "DT2precision = precision_score(resultTestSet2, DTPrediction2,average='micro') \n",
    "DT2recall = recall_score(resultTestSet2, DTPrediction2,average='weighted') \n",
    "DT2f1score = f1_score(resultTestSet2, DTPrediction2,average='macro')\n",
    "print(\"Precision of the DT Model: %.4f %%\"%(DT2precision))\n",
    "print(\"Recall of the DT Model: %.4f %%\"%(DT2recall))\n",
    "print('f1-score of the DT Model: %.4f %%'%(DT2f1score))\n",
    "\n",
    "print(\"##########Random Forest Model##########\")\n",
    "\n",
    "RFModel2=RFClass.fit(TrainSetScaled2,resultTrainSet2)\n",
    "RFPrediction2=RFModel2.predict(TestSetScaled2)\n",
    "RF2precision = precision_score(resultTestSet2, RFPrediction2,average='micro') \n",
    "RF2recall = recall_score(resultTestSet2, RFPrediction2,average='weighted') \n",
    "RF2f1score = f1_score(resultTestSet2, RFPrediction2,average='macro')\n",
    "print(\"Precision of the RF Model: %.4f %%\"%(RF2precision))\n",
    "print(\"Recall of the RF Model: %.4f %%\"%(RF2recall))\n",
    "print('f1-score of the RF Model: %.4f %%'%(RF2f1score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"##########KNN Model##########\")\n",
    "KNNModel2=KNNClass.fit(TrainSetScaled2,resultTrainSet2)\n",
    "KNNPrediction2=KNNModel2.predict(TestSetScaled2)\n",
    "KNN2precision = precision_score(resultTestSet2, KNNPrediction2,average='micro') \n",
    "KNN2recall = recall_score(resultTestSet2, KNNPrediction2,average='weighted') \n",
    "KNN2f1score = f1_score(resultTestSet2, KNNPrediction2,average='macro')\n",
    "print(\"Precision of the KNN Model: %.4f %%\"%(KNN2precision))\n",
    "print(\"Recall of the KNN Model: %.4f %%\"%(KNN2recall))\n",
    "print('f1-score of the KNN Model: %.4f %%'%(KNN2f1score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Although for the last models the height and weight were added, the predictions were not more accurate. The Random Forest Model scored the highest with an accuracy of 93%. However, the Random Forest Model accuracy made without the two attributes : height and weight is still higher (97%). Therefore, the Random Forest Model will be chosen for the rest of this assignment. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(RFModel, open('Model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
